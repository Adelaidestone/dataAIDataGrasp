"""
æ™ºèƒ½äº§å“æ•°æ®å¤„ç†å™¨ - Smart Product Data Processor
åŠŸèƒ½ï¼šæ™ºèƒ½å¤„ç†äº§å“HTMLæ•°æ®æ–‡ä»¶
- å•ä¸ªäº§å“æ¨¡å¼ï¼šè¾“å…¥æ–‡ä»¶å¤¹ç›´æ¥åŒ…å«HTMLæ–‡ä»¶
- æ‰¹é‡äº§å“æ¨¡å¼ï¼šè¾“å…¥æ–‡ä»¶å¤¹åŒ…å«å¤šä¸ªäº§å“å­æ–‡ä»¶å¤¹
è‡ªåŠ¨æ£€æµ‹æ¨¡å¼å¹¶å¤„ç†ï¼Œç”Ÿæˆæœ€ç»ˆèšåˆæ•°æ®
"""

import os
import json
import shutil
import subprocess
import sys
from datetime import datetime
import re
from pathlib import Path

import glob

class SmartProductProcessor:
    def __init__(self, base_input_path, base_output_path="E:\\dataAI\\batch_results"):
        self.base_input_path = base_input_path
        self.base_output_path = base_output_path
        self.script_mappings = {
            'main_allplatform': 'Grabbed_Aggregated_Analytics_Data.py',
            'user_behavior': 'User_Behavior_Scraper.py',
            'revenue': 'Revenue_Scraper.py'
        }
    
    def get_folders_to_process(self):
        """è·å–éœ€è¦å¤„ç†çš„æ–‡ä»¶å¤¹åˆ—è¡¨"""
        folders = []
        try:
            for item in os.listdir(self.base_input_path):
                item_path = os.path.join(self.base_input_path, item)
                if os.path.isdir(item_path):
                    folders.append(item_path)
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {e}")
        
        return folders
    
    def identify_file_type(self, filename):
        """è¯†åˆ«HTMLæ–‡ä»¶ç±»å‹"""
        filename_lower = filename.lower()
        if 'è¡Œä¸º' in filename or 'behavior' in filename_lower or 'behaviour' in filename_lower or 'userbehavior' in filename_lower or 'userbehaivor' in filename_lower:
            return 'user_behavior'
        elif 'æ”¶å…¥' in filename or 'revenue' in filename_lower:
            return 'revenue'
        elif 'allplatform' in filename_lower or 'å…¨å¹³å°' in filename or 'ä¸‹è½½é‡' in filename:
            return 'main_allplatform'
        else:
            return 'unknown'
    
    def extract_product_name(self, filename):
        """ä»æ–‡ä»¶åæå–äº§å“åç§°"""
        # ç®€å•çš„äº§å“åæå–ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ä¼˜åŒ–
        name_parts = filename.replace('.html', '').split('_')
        if name_parts:
            return name_parts[0]
        return "Unknown Product"
    
    def analyze_folder_files(self, folder_path):
        """åˆ†ææ–‡ä»¶å¤¹ä¸­çš„HTMLæ–‡ä»¶"""
        html_files = []
        
        for file in os.listdir(folder_path):
            if file.endswith('.html'):
                file_type = self.identify_file_type(file)
                product_name = self.extract_product_name(file)
                
                html_files.append({
                    'filename': file,
                    'filepath': os.path.join(folder_path, file),
                    'file_type': file_type,
                    'product_name': product_name,
                    'script': self.script_mappings.get(file_type, 'unknown')
                })
                
                print(f"  ğŸ“„ {file} â†’ {self.script_mappings.get(file_type, 'æœªçŸ¥è„šæœ¬')}")
        
        return html_files
    
    def update_script_path(self, script_name, files):
        """æ›´æ–°è„šæœ¬ä¸­çš„HTMLæ–‡ä»¶è·¯å¾„"""
        try:
            script_path = os.path.join("E:\\dataAI", script_name)
            backup_path = script_path + ".backup"
            
            # å¤‡ä»½åŸæ–‡ä»¶
            shutil.copy2(script_path, backup_path)
            
            # è¯»å–è„šæœ¬å†…å®¹
            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if script_name in ['User_Behavior_Scraper.py']:
                # å¤šå¹³å°è„šæœ¬ - æ›´æ–°html_fileså­—å…¸
                android_file = None
                ios_file = None
                
                for file_info in files:
                    if 'android' in file_info['filename'].lower() or 'å®‰å“' in file_info['filename']:
                        android_file = file_info['filepath'].replace('\\', '\\\\')
                    elif 'ios' in file_info['filename'].lower() or 'è‹¹æœ' in file_info['filename']:
                        ios_file = file_info['filepath'].replace('\\', '\\\\')
                    else:
                        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å¹³å°æ ‡è¯†ï¼Œé»˜è®¤ä¸ºAndroid
                        if not android_file:
                            android_file = file_info['filepath'].replace('\\', '\\\\')
                
                if android_file or ios_file:
                    # æ„å»ºæ–°çš„html_fileså­—å…¸
                    new_html_files = "html_files = {\n"
                    if android_file:
                        new_html_files += f'    "Android": r"{android_file}",\n'
                    if ios_file:
                        new_html_files += f'    "iOS": r"{ios_file}"\n'
                    new_html_files += "}"
                    
                    # æ›¿æ¢html_fileså­—å…¸
                    pattern = r'html_files\s*=\s*\{[^}]*\}'
                    content = re.sub(pattern, new_html_files, content, flags=re.DOTALL)
            
            else:
                # å•å¹³å°è„šæœ¬ - æ›´æ–°html_file_pathå˜é‡
                if files:
                    file_path = files[0]['filepath'].replace('\\', '\\\\')
                    pattern = r'html_file_path\s*=\s*r?"[^"]*"'
                    replacement = f'html_file_path = r"{file_path}"'
                    content = re.sub(pattern, replacement, content)
            
            # å†™å›æ–‡ä»¶
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"âœ… æ›´æ–°è„šæœ¬è·¯å¾„: {script_name}")
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°è„šæœ¬è·¯å¾„å¤±è´¥ {script_name}: {e}")
            return False
    
    def restore_script_backup(self, script_name):
        """æ¢å¤è„šæœ¬å¤‡ä»½"""
        try:
            script_path = os.path.join("E:\\dataAI", script_name)
            backup_path = script_path + ".backup"
            
            if os.path.exists(backup_path):
                shutil.copy2(backup_path, script_path)
                os.remove(backup_path)
                print(f"ğŸ”„ æ¢å¤è„šæœ¬: {script_name}")
            
        except Exception as e:
            print(f"âŒ æ¢å¤è„šæœ¬å¤±è´¥ {script_name}: {e}")
    
    def run_script(self, script_name):
        """è¿è¡Œè„šæœ¬"""
        try:
            script_path = os.path.join("E:\\dataAI", script_name)
            print(f"ğŸš€ è¿è¡Œ: {script_name}")
            
            result = subprocess.run([sys.executable, script_path], 
                                  cwd="E:\\dataAI")
            
            if result.returncode == 0:
                print(f"âœ… {script_name} è¿è¡ŒæˆåŠŸ")
                return True
            else:
                print(f"âŒ {script_name} è¿è¡Œå¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿è¡Œè„šæœ¬å¤±è´¥ {script_name}: {e}")
            return False
    
    def process_revenue_files_separately(self, files):
        """å•ç‹¬å¤„ç†Revenueæ–‡ä»¶"""
        for file_info in files:
            print(f"ğŸš€ å¤„ç†Revenueæ–‡ä»¶: {file_info['filename']}")
            if self.update_script_path('Revenue_Scraper.py', [file_info]):
                self.run_script('Revenue_Scraper.py')
                self.restore_script_backup('Revenue_Scraper.py')
    
    def process_product_folder(self, product_folder_path):
        """å¤„ç†å•ä¸ªäº§å“æ–‡ä»¶å¤¹"""
        try:
            folder_name = os.path.basename(product_folder_path)
            print(f"ğŸ” åˆ†æäº§å“æ–‡ä»¶å¤¹: {folder_name}")
            
            # åˆ†ææ–‡ä»¶å¤¹ä¸­çš„HTMLæ–‡ä»¶
            html_files = self.analyze_folder_files(product_folder_path)
            
            if not html_files:
                print(f"âš ï¸ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰HTMLæ–‡ä»¶: {folder_name}")
                return False
            
            # æŒ‰è„šæœ¬åˆ†ç»„å¤„ç†
            script_groups = {}
            for file_info in html_files:
                script = file_info['script']
                if script != 'unknown':
                    if script not in script_groups:
                        script_groups[script] = []
                    script_groups[script].append(file_info)
            
            print(f"ğŸ”§ éœ€è¦è¿è¡Œ {len(script_groups)} ä¸ªè„šæœ¬")
            
            # å¤„ç†æ¯ä¸ªè„šæœ¬ç»„
            for script, files in script_groups.items():
                print(f"ğŸš€ å¤„ç†è„šæœ¬: {script}")
                
                if script == 'Revenue_Scraper.py':
                    # Revenueè„šæœ¬éœ€è¦å•ç‹¬å¤„ç†æ¯ä¸ªå¹³å°
                    self.process_revenue_files_separately(files)
                else:
                    # å…¶ä»–è„šæœ¬æ”¯æŒåŒå¹³å°
                    if self.update_script_path(script, files):
                        self.run_script(script)
                        self.restore_script_backup(script)
            
            # ç›´æ¥ä¿å­˜äº§å“æ•°æ®å¹¶æ¸…ç†åŸå§‹æ–‡ä»¶
            self.save_product_data_from_aggregator()
            self.cleanup_raw_data()
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†äº§å“æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {e}")
            return False
    
    def save_product_data_from_aggregator(self):
        """ç›´æ¥ä»å„ä¸ªè„šæœ¬è¾“å‡ºç”Ÿæˆäº§å“æ•°æ®æ–‡ä»¶"""
        print("ğŸ”„ ç”Ÿæˆæœ€ç»ˆèšåˆæ•°æ®...")
        
        try:
            # ç›´æ¥ä»å„ä¸ªè„šæœ¬çš„è¾“å‡ºæ–‡ä»¶æ•´åˆæ•°æ®
            files = {
                'grabbed': 'Aggregated_Analytics_Data.json',
                'revenue': 'PolyBuzz_Revenue_Aggregated_Analytics_Data.json',
                'user_behavior': 'User_Behavior_Combined_Analytics_Data.json'
            }
            
            # åŠ è½½æ•°æ®æ–‡ä»¶
            data = {}
            for key, file_path in files.items():
                if os.path.exists(file_path):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data[key] = json.load(f)
                    except:
                        data[key] = None
                else:
                    data[key] = None
            
            # è·å–åº”ç”¨åç§°
            app_name = "Unknown_Application"
            for source_data in data.values():
                if source_data and isinstance(source_data, dict):
                    if 'Application' in source_data:
                        app_name = source_data['Application']
                        break
                elif source_data and isinstance(source_data, list) and len(source_data) > 0:
                    if 'Application' in source_data[0]:
                        app_name = source_data[0]['Application']
                        break
            
            # åˆ›å»ºèšåˆæ•°æ®ç»“æ„
            aggregated_data = [{
                "Application": app_name,
                "Last Updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "Data Sources": {
                    "Downloads & Basic Metrics": "Available" if data['grabbed'] else "Not Available",
                    "Revenue Data": "Available" if data['revenue'] else "Not Available", 
                    "User Behavior Data": "Available" if data['user_behavior'] else "Not Available"
                },
                "Platforms": self.build_platform_data(data)
            }]
            
            # æ¸…ç†äº§å“åç§°ï¼Œç”¨äºæ–‡ä»¶å
            import re
            clean_name = re.sub(r'[^\w\s-]', '', app_name).strip()
            clean_name = re.sub(r'[-\s]+', '_', clean_name)
            
            # ç›´æ¥ä¿å­˜åˆ°æœ€ç»ˆè¾“å‡ºç›®å½•
            final_output_dir = r"D:\Users\Mussy\Desktop\result"
            os.makedirs(final_output_dir, exist_ok=True)
            
            product_file = f"Product_{clean_name}_Data.json"
            product_path = os.path.join(final_output_dir, product_file)
            
            with open(product_path, 'w', encoding='utf-8') as f:
                json.dump(aggregated_data, f, ensure_ascii=False, indent=4)
            
            print(f"âœ… æœ€ç»ˆèšåˆæ•°æ®ç”ŸæˆæˆåŠŸ")
            print(f"ğŸ’¾ äº§å“æ•°æ®å·²ä¿å­˜åˆ°: {product_path}")
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæœ€ç»ˆèšåˆæ•°æ®æ—¶å‡ºé”™: {e}")
    
    def build_platform_data(self, data):
        """æ„å»ºå¹³å°æ•°æ®ç»“æ„"""
        platforms = {}
        
        # ä»grabbedæ•°æ®è·å–åŸºç¡€å¹³å°ç»“æ„
        if data['grabbed'] and isinstance(data['grabbed'], list) and len(data['grabbed']) > 0:
            base_app_data = data['grabbed'][0]
            platforms = base_app_data.get('Platforms', {})
        
        # æ·»åŠ ç”¨æˆ·è¡Œä¸ºæ•°æ®
        if data['user_behavior'] and 'Platforms' in data['user_behavior']:
            for platform_name, behavior_data in data['user_behavior']['Platforms'].items():
                if platform_name not in platforms:
                    platforms[platform_name] = {}
                
                # æ·»åŠ ç”¨æˆ·è¡Œä¸ºæ•°æ®
                if 'User Behavior Data' in behavior_data:
                    platforms[platform_name]['User Behavior by Country'] = behavior_data['User Behavior Data']
        
        return platforms
    
    def run_simple_data_separator(self):
        """è¿è¡Œç®€å•æ•°æ®åˆ†ç¦»å™¨"""
        try:
            separator_path = os.path.join("E:\\dataAI", "Simple_Data_Separator.py")
            if os.path.exists(separator_path):
                result = subprocess.run([sys.executable, separator_path], cwd="E:\\dataAI")
                if result.returncode == 0:
                    print("âœ… æ•°æ®åˆ†ç¦»æˆåŠŸ")
                else:
                    print("âŒ æ•°æ®åˆ†ç¦»å¤±è´¥")
            else:
                print("âŒ ç®€å•æ•°æ®åˆ†ç¦»å™¨ä¸å­˜åœ¨")
        except Exception as e:
            print(f"âŒ è¿è¡Œæ•°æ®åˆ†ç¦»å™¨å¤±è´¥: {e}")
    
    def cleanup_raw_data(self):
        """æ¸…ç†åŸå§‹æ•°æ®æ–‡ä»¶"""
        print("ğŸ§¹ æ¸…ç†åŸå§‹æ•°æ®æ–‡ä»¶...")
        
        try:
            main_dir = "E:\\dataAI"
            
            # åˆ é™¤åŸå§‹JSONæ–‡ä»¶
            json_patterns = [
                'Aggregated_Analytics_Data.json',
                'User_Behavior_*.json',
                'PolyBuzz_*.json'
            ]
            
            cleaned_files = 0
            for pattern in json_patterns:
                for file_path in glob.glob(os.path.join(main_dir, pattern)):
                    os.remove(file_path)
                    cleaned_files += 1
                    print(f"ğŸ—‘ï¸ åˆ é™¤: {os.path.basename(file_path)}")
            
            print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_files} ä¸ªåŸå§‹æ–‡ä»¶")
            
        except Exception as e:
            print(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    

    def process_all_folders(self):
        """æ™ºèƒ½å¤„ç†è¾“å…¥æ–‡ä»¶å¤¹ - è‡ªåŠ¨åˆ¤æ–­å•ä¸ªäº§å“è¿˜æ˜¯å¤šä¸ªäº§å“"""
        
        
        # å…ˆæ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹æ˜¯å¦ç›´æ¥åŒ…å«HTMLæ–‡ä»¶
        html_files_in_root = [f for f in os.listdir(self.base_input_path) 
                             if f.endswith('.html') and os.path.isfile(os.path.join(self.base_input_path, f))]
        
        if html_files_in_root:
            # å¦‚æœæ ¹ç›®å½•ç›´æ¥åŒ…å«HTMLæ–‡ä»¶ï¼Œè¯´æ˜è¿™æ˜¯å•ä¸ªäº§å“æ–‡ä»¶å¤¹
            print("ğŸ¯ æ£€æµ‹åˆ°å•ä¸ªäº§å“æ¨¡å¼ - è¾“å…¥æ–‡ä»¶å¤¹ç›´æ¥åŒ…å«HTMLæ–‡ä»¶")
            print("=" * 80)
            success = self.process_product_folder(self.base_input_path)
            
            if success:
                successful_products = [os.path.basename(self.base_input_path)]
                print(f"âœ… äº§å“å¤„ç†æˆåŠŸ")
            else:
                successful_products = []
                print(f"âŒ äº§å“å¤„ç†å¤±è´¥")
        else:
            # å¦‚æœæ ¹ç›®å½•ä¸åŒ…å«HTMLæ–‡ä»¶ï¼Œè¯´æ˜æ˜¯å¤šä¸ªäº§å“æ–‡ä»¶å¤¹çš„æ‰¹é‡æ¨¡å¼
            folders = self.get_folders_to_process()
            
            if not folders:
                print(f"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸­æ—¢æ²¡æœ‰HTMLæ–‡ä»¶ï¼Œä¹Ÿæ²¡æœ‰å­æ–‡ä»¶å¤¹: {self.base_input_path}")
                return
            
            print(f"ğŸ¯ æ£€æµ‹åˆ°æ‰¹é‡äº§å“æ¨¡å¼ - æ‰¾åˆ° {len(folders)} ä¸ªäº§å“æ–‡ä»¶å¤¹")
            print("=" * 80)
            
            successful_products = []
            
            for i, folder_path in enumerate(folders, 1):
                folder_name = os.path.basename(folder_path)
                print(f"\nğŸš€ [{i}/{len(folders)}] å¼€å§‹å¤„ç†äº§å“: {folder_name}")
                print("=" * 80)
                
                try:
                    success = self.process_product_folder(folder_path)
                    if success:
                        successful_products.append(folder_name)
                        print(f"âœ… äº§å“ '{folder_name}' å¤„ç†æˆåŠŸ")
                    else:
                        print(f"âŒ äº§å“ '{folder_name}' å¤„ç†å¤±è´¥")
                except Exception as e:
                    print(f"âŒ å¤„ç†äº§å“æ–‡ä»¶å¤¹ '{folder_name}' æ—¶å‡ºé”™: {e}")
                    continue
        
        # å¤„ç†å®Œæ‰€æœ‰äº§å“åï¼Œä½¿ç”¨ç®€å•æ•°æ®åˆ†ç¦»å™¨
        if successful_products:
            print(f"\nğŸ”„ ä½¿ç”¨ç®€å•æ•°æ®åˆ†ç¦»å™¨å¤„ç† {len(successful_products)} ä¸ªäº§å“æ•°æ®...")
            self.run_simple_data_separator()
        
        # ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
        self.generate_batch_summary(successful_products)
    
    def generate_batch_summary(self, successful_products):
        """ç”Ÿæˆæ‰¹é‡å¤„ç†çš„æ€»ç»“æŠ¥å‘Š"""
        summary = {
            "Batch_Processing_Summary": {
                "Processing_Time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "Base_Input_Path": self.base_input_path,
                "Base_Output_Path": "E:\\dataAI",  # æœ€ç»ˆèšåˆæ•°æ®çš„ä½ç½®
                "Successful_Products": successful_products,
                "Total_Products_Processed": len(successful_products),
                "Final_Output_Files": []
            }
        }
        
        # æ”¶é›†æœ€ç»ˆèšåˆæ•°æ®æ–‡ä»¶
        final_files = [
            "Complete_Products_Data.json",
            "Incomplete_Products_Data.json"
        ]
        
        summary["Batch_Processing_Summary"]["Final_Output_Files"] = final_files
        
        # ä¿å­˜æ€»ç»“æŠ¥å‘Šåˆ°ç›®æ ‡ç›®å½•
        final_output_dir = r"D:\Users\Mussy\Desktop\result"
        os.makedirs(final_output_dir, exist_ok=True)
        summary_path = os.path.join(final_output_dir, 'Batch_Processing_Summary.json')
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=4)
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
        print(f"ğŸ“Š æˆåŠŸå¤„ç†äº† {len(successful_products)} ä¸ªäº§å“:")
        for product in successful_products:
            print(f"   âœ… {product}")
        print(f"ğŸ“Š æ€»ç»“æŠ¥å‘Š: {summary_path}")
        print(f"ğŸ“ æœ€ç»ˆèšåˆæ•°æ®: D:\\Users\\Mussy\\Desktop\\result")
        
        # æ‰€æœ‰æ•°æ®å·²ç›´æ¥è¾“å‡ºåˆ°ç›®æ ‡ç›®å½•ï¼Œæ— éœ€å¤åˆ¶
    

def main():
    """ä¸»å‡½æ•°"""
    
    # ========================================
    # ğŸ”§ åœ¨è¿™é‡Œè®¾ç½®æ‚¨çš„è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
    # ========================================
    INPUT_FOLDER = r"D:\Users\Mussy\Desktop\input"  # ğŸ“‚ ä¿®æ”¹ä¸ºæ‚¨çš„è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
    
    # å¯é€‰ï¼šè®¾ç½®ä¸´æ—¶è¾“å‡ºè·¯å¾„ï¼ˆæœ€ç»ˆèšåˆæ•°æ®å§‹ç»ˆä¿å­˜åˆ° E:\dataAI\ï¼‰
    TEMP_OUTPUT = r"D:\Users\Mussy\Desktop\result"
    
    # ========================================
    
    if not os.path.exists(INPUT_FOLDER):
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {INPUT_FOLDER}")
        print("ğŸ’¡ è¯·åœ¨è„šæœ¬ä¸­ä¿®æ”¹ INPUT_FOLDER å˜é‡ä¸ºæ­£ç¡®çš„è·¯å¾„")
        return
    
    print("ğŸ¯ æ™ºèƒ½äº§å“æ•°æ®å¤„ç†å™¨")
    print("=" * 60)
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {INPUT_FOLDER}")
    print(f"ğŸ“Š æœ€ç»ˆèšåˆæ•°æ®ä½ç½®: E:\\dataAI\\")
    print(f"ğŸ“ ä¸´æ—¶å¤„ç†ç›®å½•: {TEMP_OUTPUT}")
    print("ğŸ¤– è‡ªåŠ¨æ£€æµ‹: å•ä¸ªäº§å“ æˆ– æ‰¹é‡äº§å“")
    print("=" * 60)
    
    processor = SmartProductProcessor(INPUT_FOLDER, TEMP_OUTPUT)
    processor.process_all_folders()

if __name__ == "__main__":
    main()