import json
import os
import subprocess
import sys
import argparse
from datetime import datetime

def run_scraper_script(script_name):
    """
    Run a scraper script and return success status
    """
    try:
        print(f"ğŸš€ è¿è¡Œè„šæœ¬: {script_name}")
        
        # ä½¿ç”¨æœ€ç®€å•çš„æ–¹æ³• - ä¸æ•è·è¾“å‡ºï¼Œè®©è„šæœ¬ç›´æ¥è¾“å‡ºåˆ°æ§åˆ¶å°
        result = subprocess.run([sys.executable, script_name])
        
        if result.returncode == 0:
            print(f"âœ… {script_name} è¿è¡ŒæˆåŠŸ")
            return True
        else:
            print(f"âŒ {script_name} è¿è¡Œå¤±è´¥ (é€€å‡ºä»£ç : {result.returncode})")
            return False
    except Exception as e:
        print(f"âŒ è¿è¡Œ {script_name} æ—¶å‡ºé”™: {e}")
        return False

def load_json_file(file_path):
    """
    Load JSON data from file if it exists
    """
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
            return None
    else:
        print(f"File not found: {file_path}")
        return None

def run_all_scrapers():
    """
    Run all scraper scripts to get fresh data
    """
    scrapers = {
        'Grabbed_Aggregated_Analytics_Data.py': 'Aggregated_Analytics_Data.json',
        'Revenue_Scraper.py': 'PolyBuzz_Revenue_Aggregated_Analytics_Data.json',
        'User_Behavior_Scraper.py': 'User_Behavior_Combined_Analytics_Data.json',
        'User_Retention_Scraper.py': 'PolyBuzz_User_Retention_Combined_Analytics_Data.json'
    }
    
    print("=" * 60)
    print("ğŸ”„ å¼€å§‹è¿è¡Œæ‰€æœ‰æ•°æ®æŠ“å–è„šæœ¬...")
    print("=" * 60)
    
    results = {}
    for script, expected_output in scrapers.items():
        if os.path.exists(script):
            success = run_scraper_script(script)
            results[script] = {
                'success': success,
                'output_file': expected_output,
                'output_exists': os.path.exists(expected_output) if success else False
            }
        else:
            print(f"âš ï¸  è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script}")
            results[script] = {
                'success': False,
                'output_file': expected_output,
                'output_exists': False
            }
    
    print("\n" + "=" * 60)
    print("ğŸ“Š è„šæœ¬è¿è¡Œç»“æœæ±‡æ€»:")
    print("=" * 60)
    
    for script, result in results.items():
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
        output_status = "âœ… å·²ç”Ÿæˆ" if result['output_exists'] else "âŒ æœªç”Ÿæˆ"
        print(f"{script:<35} | {status:<8} | è¾“å‡ºæ–‡ä»¶: {output_status}")
    
    successful_runs = sum(1 for r in results.values() if r['success'])
    total_runs = len(results)
    
    print(f"\nğŸ“ˆ æ€»è®¡: {successful_runs}/{total_runs} ä¸ªè„šæœ¬æˆåŠŸè¿è¡Œ")
    print("=" * 60)
    
    return results

def aggregate_all_data():
    """
    Aggregate data from all scraper outputs into a unified structure
    """
    # Define file paths
    files = {
        'grabbed': 'Aggregated_Analytics_Data.json',
        'revenue': 'PolyBuzz_Revenue_Aggregated_Analytics_Data.json',
        'user_behavior': 'User_Behavior_Combined_Analytics_Data.json',
        'user_retention': 'PolyBuzz_User_Retention_Combined_Analytics_Data.json'
    }
    
    # Load all data files
    data = {}
    for key, file_path in files.items():
        data[key] = load_json_file(file_path)
    
    # Initialize the aggregated structure
    aggregated_data = []
    
    # Get application info from any available source
    app_name = "Unknown Application"
    platforms = {}
    
    # Extract application name and platform info
    for source_data in data.values():
        if source_data and isinstance(source_data, dict):
            if 'Application' in source_data:
                app_name = source_data['Application']
                break
        elif source_data and isinstance(source_data, list) and len(source_data) > 0:
            if 'Application' in source_data[0]:
                app_name = source_data[0]['Application']
                break
    
    # Build platform-specific data structure
    # Start with existing grabbed data structure if available
    if data['grabbed'] and isinstance(data['grabbed'], list) and len(data['grabbed']) > 0:
        base_app_data = data['grabbed'][0]
        platforms = base_app_data.get('Platforms', {})
    else:
        # Create basic platform structure
        platforms = {
            "Android": {},
            "iOS": {}
        }
    
    # Add revenue data
    if data['revenue']:
        revenue_info = data['revenue']
        platform_key = "Android" if revenue_info.get('Platform') == "Google Play" else "iOS"
        
        if platform_key not in platforms:
            platforms[platform_key] = {}
            
        # Add revenue data to the appropriate platform
        if 'Revenue Data' in revenue_info and revenue_info['Revenue Data']:
            platforms[platform_key]['Average Store Revenue'] = revenue_info['Revenue Data'][0].get('Average Store Revenue', 0)
            platforms[platform_key]['Device Info'] = revenue_info['Revenue Data'][0].get('Device', 'Unknown Device')
    
    # Add user behavior data (now handles combined data)
    if data['user_behavior']:
        behavior_info = data['user_behavior']
        
        # Check if it's combined data format
        if 'Platforms' in behavior_info:
            # New combined format
            for platform_name, platform_data in behavior_info['Platforms'].items():
                platform_key = platform_name  # Use the key directly (Android/iOS)
                
                if platform_key not in platforms:
                    platforms[platform_key] = {}
                
                if 'User Behavior Data' in platform_data and platform_data['User Behavior Data']:
                    behavior_data = platform_data['User Behavior Data']
                    
                    # Find global data (å…¨çƒ)
                    global_data = next((item for item in behavior_data if item.get('Country/Region') == 'å…¨çƒ'), None)
                    if global_data:
                        if 'Active Users' in global_data:
                            platforms[platform_key]['Active Users from Behavior'] = global_data['Active Users']
                        if 'User Share' in global_data:
                            platforms[platform_key]['User Share'] = global_data['User Share']
                        if 'Avg Time Per User' in global_data:
                            platforms[platform_key]['Avg Time Per User'] = global_data['Avg Time Per User']
                    
                    # Add country breakdown
                    platforms[platform_key]['User Behavior by Country'] = behavior_data
        else:
            # Old single platform format (for backward compatibility)
            platform_key = "Android" if behavior_info.get('Platform') == "Google Play" else "iOS"
            
            if platform_key not in platforms:
                platforms[platform_key] = {}
                
            # Add user behavior summary
            if 'User Behavior Data' in behavior_info and behavior_info['User Behavior Data']:
                behavior_data = behavior_info['User Behavior Data']
                
                # Find global data (å…¨çƒ)
                global_data = next((item for item in behavior_data if item.get('Country/Region') == 'å…¨çƒ'), None)
                if global_data:
                    if 'Active Users' in global_data:
                        platforms[platform_key]['Active Users from Behavior'] = global_data['Active Users']
                    if 'User Share' in global_data:
                        platforms[platform_key]['User Share'] = global_data['User Share']
                    if 'Avg Time Per User' in global_data:
                        platforms[platform_key]['Avg Time Per User'] = global_data['Avg Time Per User']
                
                # Add country breakdown
                platforms[platform_key]['User Behavior by Country'] = behavior_data
    
    # Add user retention data (now handles combined data)
    if data['user_retention']:
        retention_info = data['user_retention']
        
        # Check if it's combined data format
        if 'Platforms' in retention_info:
            # New combined format
            for platform_name, platform_data in retention_info['Platforms'].items():
                platform_key = platform_name  # Use the key directly (Android/iOS)
                
                if platform_key not in platforms:
                    platforms[platform_key] = {}
                
                # Add retention data
                if 'Monthly App Retention' in platform_data:
                    platforms[platform_key]['Monthly Retention'] = platform_data['Monthly App Retention']
                if 'Publisher Apps User Retention (Overall)' in platform_data:
                    platforms[platform_key]['Overall Retention'] = platform_data['Publisher Apps User Retention (Overall)']
        else:
            # Old single platform format (for backward compatibility)
            platform_key = "Android" if retention_info.get('Platform') == "Google Play" else "iOS"
            
            if platform_key not in platforms:
                platforms[platform_key] = {}
                
            # Add retention data
            if 'Monthly App Retention' in retention_info:
                platforms[platform_key]['Monthly Retention'] = retention_info['Monthly App Retention']
            if 'Publisher Apps User Retention (Overall)' in retention_info:
                platforms[platform_key]['Overall Retention'] = retention_info['Publisher Apps User Retention (Overall)']
    
    # Create the final aggregated structure
    aggregated_app_data = {
        "Application": app_name,
        "Last Updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "Data Sources": {
            "Downloads & Basic Metrics": "Available" if data['grabbed'] else "Not Available",
            "Revenue Data": "Available" if data['revenue'] else "Not Available", 
            "User Behavior Data": "Available" if data['user_behavior'] else "Not Available",
            "User Retention Data": "Available" if data['user_retention'] else "Not Available"
        },
        "Platforms": platforms
    }
    
    aggregated_data.append(aggregated_app_data)
    
    return aggregated_data

def main():
    """
    Main function to run the data aggregation
    """
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='æ•°æ®æ•´åˆå·¥å…· - PolyBuzz Analytics Data Aggregator')
    parser.add_argument('--run-scrapers', '-r', action='store_true', 
                       help='å…ˆè¿è¡Œæ‰€æœ‰æŠ“å–è„šæœ¬ï¼Œç„¶åæ•´åˆæ•°æ®')
    parser.add_argument('--skip-scrapers', '-s', action='store_true', 
                       help='è·³è¿‡è¿è¡ŒæŠ“å–è„šæœ¬ï¼Œä»…æ•´åˆç°æœ‰æ•°æ®æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ”¥ æ•°æ®æ•´åˆå·¥å…· - PolyBuzz Analytics Data Aggregator")
    print("=" * 80)
    
    # Determine run mode
    if args.run_scrapers:
        choice = '2'
        print("ğŸ“‹ å‘½ä»¤è¡Œå‚æ•°ï¼šè¿è¡ŒæŠ“å–è„šæœ¬æ¨¡å¼")
    elif args.skip_scrapers:
        choice = '1'
        print("ğŸ“‹ å‘½ä»¤è¡Œå‚æ•°ï¼šè·³è¿‡æŠ“å–è„šæœ¬æ¨¡å¼")
    else:
        # Interactive mode
        print("\né€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. ä»…æ•´åˆç°æœ‰æ•°æ®æ–‡ä»¶")
        print("2. å…ˆè¿è¡Œæ‰€æœ‰æŠ“å–è„šæœ¬ï¼Œç„¶åæ•´åˆæ•°æ® (æ¨è)")
        print("\nğŸ’¡ æç¤ºï¼šä¹Ÿå¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°:")
        print("   python Data_Aggregator.py --run-scrapers     (è¿è¡ŒæŠ“å–è„šæœ¬)")
        print("   python Data_Aggregator.py --skip-scrapers    (è·³è¿‡æŠ“å–è„šæœ¬)")
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹© (1 æˆ– 2): ").strip()
                if choice in ['1', '2']:
                    break
                else:
                    print("è¯·è¾“å…¥ 1 æˆ– 2")
            except KeyboardInterrupt:
                print("\n\næ“ä½œå·²å–æ¶ˆ")
                return
    
    if choice == '2':
        print("\nğŸ”„ å°†å…ˆè¿è¡Œæ‰€æœ‰æ•°æ®æŠ“å–è„šæœ¬...")
        scraper_results = run_all_scrapers()
        
        # Check if any scrapers failed
        failed_scrapers = [script for script, result in scraper_results.items() if not result['success']]
        if failed_scrapers:
            print(f"\nâš ï¸  ä»¥ä¸‹è„šæœ¬è¿è¡Œå¤±è´¥: {', '.join(failed_scrapers)}")
            print("å°†ä½¿ç”¨ç°æœ‰çš„æ•°æ®æ–‡ä»¶è¿›è¡Œæ•´åˆ...")
    else:
        print("\nğŸ“ ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶è¿›è¡Œæ•´åˆ...")
    
    print("\n" + "=" * 60)
    print("ğŸ“Š å¼€å§‹æ•°æ®æ•´åˆ...")
    print("=" * 60)
    
    # Aggregate all data
    aggregated_data = aggregate_all_data()
    
    # Save to output file
    output_file = "Comprehensive_Aggregated_Analytics_Data.json"
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(aggregated_data, f, ensure_ascii=False, indent=4)
        
        print(f"\nâœ… æ•°æ®æ•´åˆå®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š{output_file}")
        print(f"ğŸ“Š æ•´åˆçš„åº”ç”¨æ•°é‡ï¼š{len(aggregated_data)}")
        
        # Print summary
        if aggregated_data:
            app_data = aggregated_data[0]
            print(f"ğŸ“± åº”ç”¨åç§°ï¼š{app_data['Application']}")
            print(f"ğŸ•’ æ›´æ–°æ—¶é—´ï¼š{app_data['Last Updated']}")
            print("\nğŸ“ˆ æ•°æ®æºçŠ¶æ€ï¼š")
            for source, status in app_data['Data Sources'].items():
                status_icon = "âœ…" if status == "Available" else "âŒ"
                print(f"   {status_icon} {source}: {status}")
            print(f"\nğŸ”§ å¹³å°æ•°é‡ï¼š{len(app_data['Platforms'])}")
            print("=" * 60)
            
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")

if __name__ == "__main__":
    main()
